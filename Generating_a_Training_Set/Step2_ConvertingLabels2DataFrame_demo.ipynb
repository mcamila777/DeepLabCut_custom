{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "A Mathis, alexander.mathis@bethgelab.org & M Mathis, mackenzie@post.harvard.edu\n",
    "\n",
    "This script generates a data structure in pandas, that contains the (relative) physical\n",
    "address of the image as well as the labels. These data are extracted from the \"labeling.csv\" files that\n",
    "can be generated in a different file e.g. ImageJ / Fiji. See readme for details. \n",
    "\n",
    "Load data from individial folders with a Task and combine in one panda dataframe.\n",
    "Keys of panda frame:\n",
    "    - scorer\n",
    "    - bodypart\n",
    "    - x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "sys.path.append(os.getcwd().split('Generating_a_Training_Set')[0])\n",
    "from myconfig import Task, bodyparts, Scorers, invisibleboundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n",
      "['knee']\n",
      "['camila']\n"
     ]
    }
   ],
   "source": [
    "# check relevant global variables: \n",
    "print(Task)\n",
    "print(bodyparts)\n",
    "print(Scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loading folder ', 'single_images_00')\n",
      "('Done with folder ', 'single_images_00')\n",
      "('Loading folder ', 'single_images_01')\n",
      "('Done with folder ', 'single_images_01')\n",
      "('Loading folder ', 'video_00')\n",
      "('Done with folder ', 'video_00')\n",
      "('Loading folder ', 'video_01')\n",
      "('Done with folder ', 'video_01')\n",
      "('Loading folder ', 'video_02')\n",
      "('Done with folder ', 'video_02')\n",
      "('Loading folder ', 'video_03')\n",
      "('Done with folder ', 'video_03')\n",
      "('Loading folder ', 'video_04')\n",
      "('Done with folder ', 'video_04')\n",
      "('Loading folder ', 'video_05')\n",
      "('Done with folder ', 'video_05')\n",
      "('Loading folder ', 'video_06')\n",
      "('Done with folder ', 'video_06')\n",
      "('Loading folder ', 'video_07')\n",
      "('Done with folder ', 'video_07')\n",
      "('Loading folder ', 'video_08')\n",
      "('Done with folder ', 'video_08')\n",
      "('Loading folder ', 'video_09')\n",
      "('Done with folder ', 'video_09')\n",
      "('Loading folder ', 'video_10')\n",
      "('Done with folder ', 'video_10')\n",
      "('Loading folder ', 'video_11')\n",
      "('Done with folder ', 'video_11')\n",
      "('Loading folder ', 'video_12')\n",
      "('Done with folder ', 'video_12')\n",
      "('Loading folder ', 'video_13')\n",
      "('Done with folder ', 'video_13')\n",
      "('Loading folder ', 'video_14')\n",
      "('Done with folder ', 'video_14')\n",
      "('Loading folder ', 'video_15')\n",
      "('Done with folder ', 'video_15')\n",
      "('Loading folder ', 'video_16')\n",
      "('Done with folder ', 'video_16')\n",
      "('Loading folder ', 'video_17')\n",
      "('Done with folder ', 'video_17')\n",
      "('Loading folder ', 'video_18')\n",
      "('Done with folder ', 'video_18')\n",
      "Merging scorer's data.\n"
     ]
    }
   ],
   "source": [
    "basefolder='data-'+Task+'/'\n",
    "\n",
    "DataCombined=None #Data frame to hold data of all data sets for different scorers, bodyparts and images\n",
    "\n",
    "for scorer in Scorers:\n",
    "    os.chdir(basefolder)\n",
    "    #Make list of different video data sets / each one has its own folder\n",
    "    folders=[videodatasets for videodatasets in os.listdir(os.curdir) if os.path.isdir(videodatasets)==True and\n",
    "     'labeled' not in videodatasets]       \n",
    "    try: \n",
    "        #print ('try')\n",
    "        DataSingleUser=pd.read_hdf('CollectedData_'+scorer+'.h5', 'df_with_missing')\n",
    "        numdistinctfolders=list(set([s.split('/')[0] for s in DataSingleUser.index])) #NOTE: SLICING to eliminate multiindices!\n",
    "        #print(\"found\",len(folders),len(numdistinctfolders))\n",
    "        if len(folders)>len(numdistinctfolders):\n",
    "            DataSingleUsers=None\n",
    "            print(\"Not all data converted!\")\n",
    "        else:\n",
    "            print(scorer,\"'s data already collected!\")\n",
    "            #print(DataSingleUser.head())    \n",
    "    except:\n",
    "        #print ('except')\n",
    "        DataSingleUser=None    \n",
    "\n",
    "    \n",
    "    if DataSingleUser is None:    \n",
    "        for folder in folders:\n",
    "            print(\"Loading folder \", folder)\n",
    "            os.chdir(folder)\n",
    "            # sort image file names according to how they were stacked\n",
    "            \n",
    "            #files=[fn for fn in os.listdir(os.curdir) if (\"img\" in fn and \".png\" in fn and \"_labelled\" not in fn)]\n",
    "            files=[fn for fn in os.listdir(os.curdir) if (\"frame\" in fn and \".png\" in fn and \"_labelled\" not in fn)]\n",
    "\n",
    "            files.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "            \n",
    "            imageaddress=[folder+'/'+f for f in files]\n",
    "            Data_onefolder=pd.DataFrame({'Image name': imageaddress})\n",
    "            \n",
    "            frame,Frame=None,None\n",
    "            for bodypart in bodyparts:\n",
    "                datafile=bodypart\n",
    "                try:\n",
    "                        dframe=pd.read_csv(datafile+\".xls\" )#, sep=None,engine='python')#,sep='\\t') sep=None,engine='python'\n",
    "                        #print(dframe.head())\n",
    "                        \n",
    "                except:\n",
    "                        os.rename(datafile+\".csv\", datafile+\".xls\")\n",
    "                        dframe=pd.read_csv(datafile+\".xls\")#, sep=None,engine='python')#,sep='\\t') sep=None,engine='python'\n",
    "        \n",
    "                if dframe.shape[0]!=len(imageaddress):\n",
    "                    #Filling up with nans \n",
    "                    #dframe.set_index('Slice')\n",
    "                    new_index=pd.Index(np.arange(len(files))+1,name='Slice')\n",
    "                    dframe=dframe.set_index('Slice').reindex(new_index)\n",
    "                    dframe=dframe.reset_index()        \n",
    "             \n",
    "                #print(dframe.head())\n",
    "                #print(bodypart)\n",
    "                index = pd.MultiIndex.from_product([[scorer], [bodypart], ['x', 'y']], names=['scorer', 'bodyparts', 'coords'])\n",
    "                \n",
    "                Xrescaled=dframe.X.values.astype(float)\n",
    "                Yrescaled=dframe.Y.values.astype(float)\n",
    "                \n",
    "                #-----------------------------------------------------------------------------\n",
    "                \n",
    "                # get rid of values that are invisible >> thus user scored in left corner!\n",
    "                #invisiblemarkersmask = (Xrescaled < invisibleboundary) * (Yrescaled < invisibleboundary)\n",
    "                #Xrescaled[invisiblemarkersmask] = np.nan\n",
    "                #Yrescaled[invisiblemarkersmask] = np.nan\n",
    "                \n",
    "                #Remove data with ocluded joint (invisibleboundary)\n",
    "                \n",
    "                del_ind  =  np.where((Xrescaled < invisibleboundary) * (Yrescaled < invisibleboundary))\n",
    "                Xrescaled = np.delete(Xrescaled, del_ind ,0)\n",
    "                Yrescaled = np.delete(Yrescaled, del_ind ,0)\n",
    "                imageaddress = np.delete(imageaddress, del_ind ,0).tolist()\n",
    "                #-----------------------------------------------------------------------------\n",
    "                \n",
    "                if Frame is None:\n",
    "                    #frame=pd.DataFrame(np.vstack([dframe.X,dframe.Y]).T, columns=index,index=imageaddress)\n",
    "                    frame=pd.DataFrame(np.vstack([Xrescaled,Yrescaled]).T, columns=index,index=imageaddress)\n",
    "                    #print(frame.head())\n",
    "                    Frame=frame\n",
    "                else:\n",
    "                    \n",
    "                \n",
    "                    frame=pd.DataFrame(np.vstack([Xrescaled,Yrescaled]).T, columns=index,index=imageaddress)\n",
    "                    Frame=pd.concat([Frame,frame],axis=1) # along bodyparts & scorer dimension\n",
    "\n",
    "                \n",
    "            print(\"Done with folder \", folder)   \n",
    "            if DataSingleUser is None:\n",
    "                DataSingleUser=Frame\n",
    "            else:\n",
    "                DataSingleUser=pd.concat([DataSingleUser,Frame],axis=0) #along filenames! \n",
    "                    \n",
    "            os.chdir('../')\n",
    "        \n",
    "        # Save data by this scorer\n",
    "        DataSingleUser.to_csv(\"CollectedData_\"+scorer+\".csv\") #breaks multi-indices HDF5 tables better!\n",
    "        DataSingleUser.to_hdf('CollectedData_'+scorer+'.h5', 'df_with_missing',format = 'table', mode='w')\n",
    "        \n",
    "    os.chdir('../')\n",
    "    \n",
    "    print(\"Merging scorer's data.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
