{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanyaMay24-trainset70shuffle2  -  DeepCut_resnetresnet_50_70shuffle2_130000forTask:tanya\n",
    "#snapshot-130000\n",
    "\n",
    "snapshot =  'snapshot-130000'\n",
    "\n",
    "shuffleIndex =  2\n",
    "\n",
    "trainFractionIndex =  0  #int(sys.argv[3])\n",
    "\n",
    "test_images_path = '/is/ps2/calvarez2/DeepLabCut/test_images/images'\n",
    "labeled_images_path = '/is/ps2/calvarez2/DeepLabCut/test_images/labeled_images'\n",
    "\n",
    "max_input_size = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Camila modification --\n",
    "\n",
    "DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "A Mathis, alexander.mathis@bethgelab.org\n",
    "M Mathis, mackenzie@post.harvard.edu\n",
    "This script evaluates a trained model at a particular state on the data set (images)\n",
    "and stores the results in a pandas dataframe.\n",
    "Script called from Step1_EvaluateModelonDataset.py\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "subfolder = os.getcwd().split('Evaluation-Tools')[0]\n",
    "sys.path.append(subfolder)\n",
    "\n",
    "\n",
    "# add parent directory: (where nnet & config are!)\n",
    "sys.path.append(subfolder + \"pose-tensorflow\")\n",
    "sys.path.append(subfolder + \"Generating_a_Training_Set\")\n",
    "\n",
    "from myconfig import Task, date, Shuffles, scorer, TrainingFraction,snapshotindex\n",
    "\n",
    "# Deep-cut dependencies\n",
    "from config import load_config\n",
    "from nnet import predict\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "# Dependencies for anaysis\n",
    "import pickle\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import skimage.color\n",
    "import auxiliaryfunctions\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(\"Starting evaluation\") #, sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle=Shuffles[shuffleIndex]\n",
    "trainFraction=TrainingFraction[trainFractionIndex]\n",
    "\n",
    "basefolder = os.path.join('..','pose-tensorflow','models')\n",
    "folder = os.path.join('UnaugmentedDataSet_' + Task + date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Running ', 'DeepCut_resnetresnet_50_70shuffle2_130000forTask:tanya', ' with # of trainingiterations:', '130000')\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# Load and setup CNN part detector as well as its configuration\n",
    "#######################################################################\n",
    "\n",
    "experimentname = Task + date + '-trainset' + str(int(trainFraction * 100)) + 'shuffle' + str(shuffle)\n",
    "cfg = load_config(os.path.join(basefolder , experimentname , 'test' ,\"pose_cfg.yaml\"))\n",
    "modelfolder = os.path.join(basefolder, experimentname)\n",
    "\n",
    "cfg['init_weights'] = os.path.join(modelfolder,'train',snapshot)\n",
    "\n",
    "trainingsiterations = (\n",
    "    cfg['init_weights'].split('/')[-1]).split('-')[-1]\n",
    "DLCscorer = 'DeepCut' + \"_resnet\" + str(cfg[\"net_type\"]) + \"_\" + str(\n",
    "    int(trainFraction *\n",
    "        100)) + 'shuffle' + str(shuffle) + '_' + str(trainingsiterations) + \"forTask:\" + Task\n",
    "\n",
    "print(\"Running \", DLCscorer, \" with # of trainingiterations:\", trainingsiterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /is/ps2/calvarez2/DeepLabCut/pose-tensorflow/nnet/pose_net.py:52: calling resnet_arg_scope (from tensorflow.contrib.slim.python.slim.nets.resnet_utils) with is_training is deprecated and will be removed after 2017-08-01.\n",
      "Instructions for updating:\n",
      "Pass is_training directly to the network instead of the arg_scope.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /is/ps2/calvarez2/DeepLabCut/pose-tensorflow/nnet/pose_net.py:52: calling resnet_arg_scope (from tensorflow.contrib.slim.python.slim.nets.resnet_utils) with is_training is deprecated and will be removed after 2017-08-01.\n",
      "Instructions for updating:\n",
      "Pass is_training directly to the network instead of the arg_scope.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../pose-tensorflow/models/tanyaMay24-trainset70shuffle2/train/snapshot-130000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../pose-tensorflow/models/tanyaMay24-trainset70shuffle2/train/snapshot-130000\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n",
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n",
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:02,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n",
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:02,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n",
      "Folder already exists!\n",
      "('Done and results stored for snapshot: ', 'snapshot-130000')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Data = pd.read_hdf(os.path.join(\"Results\",DLCscorer + '.h5'),'df_with_missing')\n",
    "    print(\"This net has already been evaluated!\")\n",
    "except :\n",
    "    # Specifying state of model (snapshot / training state)\n",
    "    cfg['init_weights'] = os.path.join(modelfolder,'train',snapshot)\n",
    "    \n",
    "    sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "    \n",
    "    \n",
    "    images_names = os.listdir(test_images_path)\n",
    "    \n",
    "    Numimages = len(images_names) #len(Data.index)\n",
    "    PredicteData = np.zeros((Numimages,3 * len(cfg['all_joints_names'])))\n",
    "    Testset = np.zeros(Numimages)\n",
    "    \n",
    "    print(\"Analyzing data...\")\n",
    "    \n",
    "    ##################################################\n",
    "    # Compute predictions over images\n",
    "    ##################################################\n",
    "    \n",
    "    for imageindex, imagename in tqdm(enumerate(images_names)):\n",
    "        image = io.imread(os.path.join(test_images_path, imagename),mode='RGB')\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "        height, width, channels = image.shape\n",
    "        if(width * height > max_input_size*max_input_size):\n",
    "                factor = (max_input_size*0.9)/max(height, width)\n",
    "                image = cv2.resize(image, None, fx = factor, fy = factor, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        image_batch = data_to_input(image)\n",
    "        \n",
    "        \n",
    "        # Compute prediction with the CNN\n",
    "        outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "        scmap, locref = predict.extract_cnn_output(outputs_np, cfg)\n",
    "        \n",
    "        # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "        pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "        PredicteData[imageindex, :] = pose.flatten(\n",
    "        )  # NOTE: thereby     cfg_test['all_joints_names'] should be same order as bodyparts!\n",
    "      \n",
    "        index = pd.MultiIndex.from_product(\n",
    "            [[DLCscorer], cfg['all_joints_names'], ['x', 'y', 'likelihood']],\n",
    "            names=['scorer', 'bodyparts', 'coords'])\n",
    "\n",
    "        # Saving results:\n",
    "        auxiliaryfunctions.attempttomakefolder(\"Results\")\n",
    "\n",
    "        DataMachine = pd.DataFrame(\n",
    "            PredicteData, columns=index, index= images_names )\n",
    "        DataMachine.to_hdf(os.path.join(\"Results\",'Test_sample_'+DLCscorer + '.h5'),'df_with_missing',format='table',mode='w')\n",
    "        print(\"Done and results stored for snapshot: \", snapshot)        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"21\" halign=\"left\">DeepCut_resnetresnet_50_70shuffle2_130000forTask:tanya</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tail tip</th>\n",
       "      <th colspan=\"3\" halign=\"left\">back right shoulder</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tail start</th>\n",
       "      <th>front left knee</th>\n",
       "      <th>...</th>\n",
       "      <th>back right foot</th>\n",
       "      <th colspan=\"3\" halign=\"left\">back left knee</th>\n",
       "      <th colspan=\"3\" halign=\"left\">right ear</th>\n",
       "      <th colspan=\"3\" halign=\"left\">back left ankle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>...</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>download.jpeg</th>\n",
       "      <td>245.382316</td>\n",
       "      <td>100.015517</td>\n",
       "      <td>0.265371</td>\n",
       "      <td>185.128766</td>\n",
       "      <td>74.701450</td>\n",
       "      <td>0.395937</td>\n",
       "      <td>223.865395</td>\n",
       "      <td>50.322142</td>\n",
       "      <td>0.096255</td>\n",
       "      <td>121.818414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118286</td>\n",
       "      <td>231.784291</td>\n",
       "      <td>113.234206</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>61.343495</td>\n",
       "      <td>11.453465</td>\n",
       "      <td>0.084508</td>\n",
       "      <td>175.521053</td>\n",
       "      <td>153.814428</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame00.png</th>\n",
       "      <td>409.653399</td>\n",
       "      <td>344.335851</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>443.690574</td>\n",
       "      <td>329.763581</td>\n",
       "      <td>0.985115</td>\n",
       "      <td>419.713856</td>\n",
       "      <td>300.987465</td>\n",
       "      <td>0.985115</td>\n",
       "      <td>487.435950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993838</td>\n",
       "      <td>436.571662</td>\n",
       "      <td>359.365816</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>495.330883</td>\n",
       "      <td>272.651004</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>436.012750</td>\n",
       "      <td>375.224007</td>\n",
       "      <td>0.999488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame016.png</th>\n",
       "      <td>345.447287</td>\n",
       "      <td>437.938692</td>\n",
       "      <td>0.801736</td>\n",
       "      <td>456.827516</td>\n",
       "      <td>376.762300</td>\n",
       "      <td>0.351176</td>\n",
       "      <td>389.137235</td>\n",
       "      <td>273.189515</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>711.372278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243947</td>\n",
       "      <td>426.258573</td>\n",
       "      <td>455.421776</td>\n",
       "      <td>0.521080</td>\n",
       "      <td>794.394336</td>\n",
       "      <td>122.110319</td>\n",
       "      <td>0.919876</td>\n",
       "      <td>346.732061</td>\n",
       "      <td>445.309906</td>\n",
       "      <td>0.012455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>download_1.jpeg</th>\n",
       "      <td>182.991820</td>\n",
       "      <td>129.773887</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>581.161192</td>\n",
       "      <td>368.587721</td>\n",
       "      <td>0.133978</td>\n",
       "      <td>489.237836</td>\n",
       "      <td>203.015867</td>\n",
       "      <td>0.047165</td>\n",
       "      <td>314.874008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>308.864637</td>\n",
       "      <td>510.295025</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>193.412937</td>\n",
       "      <td>34.499790</td>\n",
       "      <td>0.200286</td>\n",
       "      <td>591.278532</td>\n",
       "      <td>590.505276</td>\n",
       "      <td>0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame012.png</th>\n",
       "      <td>250.050290</td>\n",
       "      <td>407.790368</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>360.458504</td>\n",
       "      <td>370.573644</td>\n",
       "      <td>0.384290</td>\n",
       "      <td>282.977424</td>\n",
       "      <td>307.040377</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>554.278967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668956</td>\n",
       "      <td>550.045847</td>\n",
       "      <td>439.395159</td>\n",
       "      <td>0.744591</td>\n",
       "      <td>642.572305</td>\n",
       "      <td>240.871218</td>\n",
       "      <td>0.980358</td>\n",
       "      <td>562.638707</td>\n",
       "      <td>488.257371</td>\n",
       "      <td>0.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame018.png</th>\n",
       "      <td>417.062580</td>\n",
       "      <td>404.873541</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>429.932437</td>\n",
       "      <td>334.674234</td>\n",
       "      <td>0.977192</td>\n",
       "      <td>416.980125</td>\n",
       "      <td>292.802115</td>\n",
       "      <td>0.168163</td>\n",
       "      <td>603.450896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910618</td>\n",
       "      <td>460.396295</td>\n",
       "      <td>421.092992</td>\n",
       "      <td>0.976532</td>\n",
       "      <td>556.196054</td>\n",
       "      <td>174.782157</td>\n",
       "      <td>0.735641</td>\n",
       "      <td>454.128863</td>\n",
       "      <td>496.592935</td>\n",
       "      <td>0.135313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame068.png</th>\n",
       "      <td>279.147072</td>\n",
       "      <td>385.129313</td>\n",
       "      <td>0.991591</td>\n",
       "      <td>361.292084</td>\n",
       "      <td>343.213979</td>\n",
       "      <td>0.299136</td>\n",
       "      <td>310.241284</td>\n",
       "      <td>309.044733</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>450.966576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>318.325030</td>\n",
       "      <td>408.406442</td>\n",
       "      <td>0.733249</td>\n",
       "      <td>580.133384</td>\n",
       "      <td>258.050817</td>\n",
       "      <td>0.990806</td>\n",
       "      <td>324.402029</td>\n",
       "      <td>443.810512</td>\n",
       "      <td>0.978228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down_3.jpeg</th>\n",
       "      <td>195.184207</td>\n",
       "      <td>405.002856</td>\n",
       "      <td>0.758334</td>\n",
       "      <td>255.898971</td>\n",
       "      <td>299.718562</td>\n",
       "      <td>0.124055</td>\n",
       "      <td>185.465977</td>\n",
       "      <td>200.396163</td>\n",
       "      <td>0.898119</td>\n",
       "      <td>470.233619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048603</td>\n",
       "      <td>217.569180</td>\n",
       "      <td>432.552893</td>\n",
       "      <td>0.558775</td>\n",
       "      <td>723.676522</td>\n",
       "      <td>325.415121</td>\n",
       "      <td>0.363525</td>\n",
       "      <td>220.209508</td>\n",
       "      <td>496.152986</td>\n",
       "      <td>0.036924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down_2.jpg</th>\n",
       "      <td>65.970319</td>\n",
       "      <td>280.404025</td>\n",
       "      <td>0.777394</td>\n",
       "      <td>123.080460</td>\n",
       "      <td>221.616022</td>\n",
       "      <td>0.962826</td>\n",
       "      <td>83.110970</td>\n",
       "      <td>167.793927</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>272.421530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324583</td>\n",
       "      <td>91.617231</td>\n",
       "      <td>265.511841</td>\n",
       "      <td>0.532517</td>\n",
       "      <td>305.218133</td>\n",
       "      <td>107.845411</td>\n",
       "      <td>0.935421</td>\n",
       "      <td>85.503407</td>\n",
       "      <td>314.239683</td>\n",
       "      <td>0.953583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer          DeepCut_resnetresnet_50_70shuffle2_130000forTask:tanya  \\\n",
       "bodyparts                                                     tail tip   \n",
       "coords                                                               x   \n",
       "download.jpeg                                           245.382316       \n",
       "frame00.png                                             409.653399       \n",
       "frame016.png                                            345.447287       \n",
       "download_1.jpeg                                         182.991820       \n",
       "frame012.png                                            250.050290       \n",
       "frame018.png                                            417.062580       \n",
       "frame068.png                                            279.147072       \n",
       "down_3.jpeg                                             195.184207       \n",
       "down_2.jpg                                               65.970319       \n",
       "\n",
       "scorer                                                                  \\\n",
       "bodyparts                              back right shoulder               \n",
       "coords                    y likelihood                   x           y   \n",
       "download.jpeg    100.015517   0.265371          185.128766   74.701450   \n",
       "frame00.png      344.335851   0.986123          443.690574  329.763581   \n",
       "frame016.png     437.938692   0.801736          456.827516  376.762300   \n",
       "download_1.jpeg  129.773887   0.004649          581.161192  368.587721   \n",
       "frame012.png     407.790368   0.993865          360.458504  370.573644   \n",
       "frame018.png     404.873541   0.999113          429.932437  334.674234   \n",
       "frame068.png     385.129313   0.991591          361.292084  343.213979   \n",
       "down_3.jpeg      405.002856   0.758334          255.898971  299.718562   \n",
       "down_2.jpg       280.404025   0.777394          123.080460  221.616022   \n",
       "\n",
       "scorer                                                                         \\\n",
       "bodyparts                   tail start                        front left knee   \n",
       "coords          likelihood           x           y likelihood               x   \n",
       "download.jpeg     0.395937  223.865395   50.322142   0.096255      121.818414   \n",
       "frame00.png       0.985115  419.713856  300.987465   0.985115      487.435950   \n",
       "frame016.png      0.351176  389.137235  273.189515   0.999952      711.372278   \n",
       "download_1.jpeg   0.133978  489.237836  203.015867   0.047165      314.874008   \n",
       "frame012.png      0.384290  282.977424  307.040377   0.998956      554.278967   \n",
       "frame018.png      0.977192  416.980125  292.802115   0.168163      603.450896   \n",
       "frame068.png      0.299136  310.241284  309.044733   0.999852      450.966576   \n",
       "down_3.jpeg       0.124055  185.465977  200.396163   0.898119      470.233619   \n",
       "down_2.jpg        0.962826   83.110970  167.793927   0.878579      272.421530   \n",
       "\n",
       "scorer             ...                                                 \\\n",
       "bodyparts          ...     back right foot back left knee               \n",
       "coords             ...          likelihood              x           y   \n",
       "download.jpeg      ...            0.118286     231.784291  113.234206   \n",
       "frame00.png        ...            0.993838     436.571662  359.365816   \n",
       "frame016.png       ...            0.243947     426.258573  455.421776   \n",
       "download_1.jpeg    ...            0.021963     308.864637  510.295025   \n",
       "frame012.png       ...            0.668956     550.045847  439.395159   \n",
       "frame018.png       ...            0.910618     460.396295  421.092992   \n",
       "frame068.png       ...            0.334986     318.325030  408.406442   \n",
       "down_3.jpeg        ...            0.048603     217.569180  432.552893   \n",
       "down_2.jpg         ...            0.324583      91.617231  265.511841   \n",
       "\n",
       "scorer                                                                         \\\n",
       "bodyparts                    right ear                        back left ankle   \n",
       "coords          likelihood           x           y likelihood               x   \n",
       "download.jpeg     0.014248   61.343495   11.453465   0.084508      175.521053   \n",
       "frame00.png       0.999783  495.330883  272.651004   0.999657      436.012750   \n",
       "frame016.png      0.521080  794.394336  122.110319   0.919876      346.732061   \n",
       "download_1.jpeg   0.012532  193.412937   34.499790   0.200286      591.278532   \n",
       "frame012.png      0.744591  642.572305  240.871218   0.980358      562.638707   \n",
       "frame018.png      0.976532  556.196054  174.782157   0.735641      454.128863   \n",
       "frame068.png      0.733249  580.133384  258.050817   0.990806      324.402029   \n",
       "down_3.jpeg       0.558775  723.676522  325.415121   0.363525      220.209508   \n",
       "down_2.jpg        0.532517  305.218133  107.845411   0.935421       85.503407   \n",
       "\n",
       "scorer                                  \n",
       "bodyparts                               \n",
       "coords                    y likelihood  \n",
       "download.jpeg    153.814428   0.027130  \n",
       "frame00.png      375.224007   0.999488  \n",
       "frame016.png     445.309906   0.012455  \n",
       "download_1.jpeg  590.505276   0.002738  \n",
       "frame012.png     488.257371   0.534500  \n",
       "frame018.png     496.592935   0.135313  \n",
       "frame068.png     443.810512   0.978228  \n",
       "down_3.jpeg      496.152986   0.036924  \n",
       "down_2.jpg       314.239683   0.953583  \n",
       "\n",
       "[9 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepCut_resnetresnet_50_70shuffle2_130000forTask:tanya'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DLCscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- one image ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "#sys.path.append(os.getcwd().split('Generating_a_Training_Set')[0])\n",
    "\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['figure.figsize'] = [5,3]\n",
    "from myconfig import Task, filename, bodyparts, Scorers\n",
    "from myconfig import scorer as cfg_scorer\n",
    "\n",
    "Labels = ['.', '+', '*']  # order of labels for different scorers\n",
    "\n",
    "# https://stackoverflow.com/questions/14720331/how-to-generate-random-colors-in-matplotlib\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "Colorscheme = get_cmap(len(bodyparts))\n",
    "\n",
    "comparisonbodyparts = list(set(DataMachine.columns.get_level_values(1)))\n",
    "\n",
    "scale = 1  # for plotting\n",
    "msize = 15   #size of labels\n",
    "\n",
    "scorer_machine = DLCscorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# imagename = 'frame016.png' #'download_1.jpeg.jpeg' #'frame016.png'  #'frame016.png'\n",
    "\n",
    "for imageindex, imagename in tqdm(enumerate(images_names)):\n",
    "\n",
    "\n",
    "    imindex = np.where(\n",
    "                np.array(DataMachine.index.values) == imagename)[0]\n",
    "\n",
    "    # image = io.imread('/is/ps2/calvarez2/DeepLabCut/pose-tensorflow/models/UnaugmentedDataSet_tanyaMay24/data-tanya/' + imagename)\n",
    "    image = io.imread(os.path.join(test_images_path, imagename),mode='RGB')\n",
    "    image = skimage.color.gray2rgb(image) \n",
    "    height, width, channels = image.shape\n",
    "    if(width * height > max_input_size*max_input_size):\n",
    "        factor = (max_input_size*0.9)/max(height, width)## To Define: img name\n",
    "        image = cv2.resize(image, None, fx = factor, fy = factor, interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    plane_name , extenstion = imagename.split('.')\n",
    "\n",
    "    if extenstion != 'png':\n",
    "        imagename = plane_name + '.png'\n",
    "\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    if np.ndim(image)==2:\n",
    "        h, w = np.shape(image)\n",
    "    else:\n",
    "        h, w, nc = np.shape(image)\n",
    "\n",
    "    plt.figure(\n",
    "        frameon=False, figsize=(w * 1. / 100 * scale, h * 1. / 100 * scale))\n",
    "    plt.subplots_adjust(\n",
    "        left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.imshow(image, 'bone')\n",
    "    for cc, scorer in enumerate(Scorers):\n",
    "        for c, bp in enumerate(comparisonbodyparts):\n",
    "\n",
    "            plt.plot(   \n",
    "                    DataMachine[scorer_machine][bp]['x'].values[imindex],\n",
    "                    DataMachine[scorer_machine][bp]['y'].values[imindex],\n",
    "                    Labels[0],\n",
    "                    color=Colorscheme(c),#color=Colorscheme[c],#color=Colorscheme[0],\n",
    "                    alpha=.5,\n",
    "                    ms=msize)\n",
    "\n",
    "    plt.xlim(0, w)\n",
    "    plt.ylim(0, h)\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(\n",
    "        left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(labeled_images_path + '/' + imagename , dpi=100) #dpi=100 = original size\n",
    "    plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
