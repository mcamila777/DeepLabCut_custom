{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Camila modification --\n",
    "\n",
    "DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "A Mathis, alexander.mathis@bethgelab.org\n",
    "M Mathis, mackenzie@post.harvard.edu\n",
    "This script evaluates a trained model at a particular state on the data set (images)\n",
    "and stores the results in a pandas dataframe.\n",
    "Script called from Step1_EvaluateModelonDataset.py\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "subfolder = os.getcwd().split('Evaluation-Tools')[0]\n",
    "sys.path.append(subfolder)\n",
    "\n",
    "\n",
    "# add parent directory: (where nnet & config are!)\n",
    "sys.path.append(subfolder + \"pose-tensorflow\")\n",
    "sys.path.append(subfolder + \"Generating_a_Training_Set\")\n",
    "\n",
    "from myconfig import Task, date, Shuffles, scorer, TrainingFraction,snapshotindex\n",
    "\n",
    "# Deep-cut dependencies\n",
    "from config import load_config\n",
    "from nnet import predict\n",
    "from dataset.pose_dataset import data_to_input\n",
    "\n",
    "# Dependencies for anaysis\n",
    "import pickle\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import skimage.color\n",
    "import auxiliaryfunctions\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(\"Starting evaluation\") #, sys.argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanyaMay24-trainset70shuffle2  -  DeepCut_resnetresnet_50_70shuffle2_130000forTask:tanya\n",
    "#snapshot-130000\n",
    "\n",
    "snapshot =  'snapshot-130000'\n",
    "\n",
    "shuffleIndex =  2\n",
    "\n",
    "trainFractionIndex =  0  #int(sys.argv[3])\n",
    "\n",
    "test_images_path = '/is/ps2/calvarez2/DeepLabCut/test_images/images'\n",
    "labeled_images_path = '/is/ps2/calvarez2/DeepLabCut/test_images/labeled_images'\n",
    "\n",
    "max_input_size = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle=Shuffles[shuffleIndex]\n",
    "trainFraction=TrainingFraction[trainFractionIndex]\n",
    "\n",
    "basefolder = os.path.join('..','pose-tensorflow','models')\n",
    "folder = os.path.join('UnaugmentedDataSet_' + Task + date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Load and setup CNN part detector as well as its configuration\n",
    "#######################################################################\n",
    "\n",
    "experimentname = Task + date + '-trainset' + str(int(trainFraction * 100)) + 'shuffle' + str(shuffle)\n",
    "cfg = load_config(os.path.join(basefolder , experimentname , 'test' ,\"pose_cfg.yaml\"))\n",
    "modelfolder = os.path.join(basefolder, experimentname)\n",
    "\n",
    "cfg['init_weights'] = os.path.join(modelfolder,'train',snapshot)\n",
    "\n",
    "trainingsiterations = (\n",
    "    cfg['init_weights'].split('/')[-1]).split('-')[-1]\n",
    "DLCscorer = 'DeepCut' + \"_resnet\" + str(cfg[\"net_type\"]) + \"_\" + str(\n",
    "    int(trainFraction *\n",
    "        100)) + 'shuffle' + str(shuffle) + '_' + str(trainingsiterations) + \"forTask:\" + Task\n",
    "\n",
    "print(\"Running \", DLCscorer, \" with # of trainingiterations:\", trainingsiterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Data = pd.read_hdf(os.path.join(\"Results\",DLCscorer + '.h5'),'df_with_missing')\n",
    "    print(\"This net has already been evaluated!\")\n",
    "except :\n",
    "    # Specifying state of model (snapshot / training state)\n",
    "    cfg['init_weights'] = os.path.join(modelfolder,'train',snapshot)\n",
    "    \n",
    "    sess, inputs, outputs = predict.setup_pose_prediction(cfg)\n",
    "    \n",
    "    \n",
    "    images_names = os.listdir(test_images_path)\n",
    "    \n",
    "    Numimages = len(images_names) #len(Data.index)\n",
    "    PredicteData = np.zeros((Numimages,3 * len(cfg['all_joints_names'])))\n",
    "    Testset = np.zeros(Numimages)\n",
    "    \n",
    "    print(\"Analyzing data...\")\n",
    "    \n",
    "    ##################################################\n",
    "    # Compute predictions over images\n",
    "    ##################################################\n",
    "    \n",
    "    for imageindex, imagename in tqdm(enumerate(images_names)):\n",
    "        image = io.imread(os.path.join(test_images_path, imagename),mode='RGB')\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "        height, width, channels = image.shape\n",
    "        if(width * height > max_input_size*max_input_size):\n",
    "                factor = (max_input_size*0.9)/max(height, width)\n",
    "                image = cv2.resize(image, None, fx = factor, fy = factor, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        image_batch = data_to_input(image)\n",
    "        \n",
    "        \n",
    "        # Compute prediction with the CNN\n",
    "        outputs_np = sess.run(outputs, feed_dict={inputs: image_batch})\n",
    "        scmap, locref = predict.extract_cnn_output(outputs_np, cfg)\n",
    "        \n",
    "        # Extract maximum scoring location from the heatmap, assume 1 person\n",
    "        pose = predict.argmax_pose_predict(scmap, locref, cfg.stride)\n",
    "        PredicteData[imageindex, :] = pose.flatten(\n",
    "        )  # NOTE: thereby     cfg_test['all_joints_names'] should be same order as bodyparts!\n",
    "      \n",
    "        index = pd.MultiIndex.from_product(\n",
    "            [[DLCscorer], cfg['all_joints_names'], ['x', 'y', 'likelihood']],\n",
    "            names=['scorer', 'bodyparts', 'coords'])\n",
    "\n",
    "        # Saving results:\n",
    "        auxiliaryfunctions.attempttomakefolder(\"Results\")\n",
    "\n",
    "        DataMachine = pd.DataFrame(\n",
    "            PredicteData, columns=index, index= images_names )\n",
    "        DataMachine.to_hdf(os.path.join(\"Results\",'Test_sample_'+DLCscorer + '.h5'),'df_with_missing',format='table',mode='w')\n",
    "        print(\"Done and results stored for snapshot: \", snapshot)        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLCscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- one image ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "#sys.path.append(os.getcwd().split('Generating_a_Training_Set')[0])\n",
    "\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['figure.figsize'] = [5,3]\n",
    "from myconfig import Task, filename, bodyparts, Scorers\n",
    "from myconfig import scorer as cfg_scorer\n",
    "\n",
    "Labels = ['.', '+', '*']  # order of labels for different scorers\n",
    "\n",
    "# https://stackoverflow.com/questions/14720331/how-to-generate-random-colors-in-matplotlib\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct\n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "Colorscheme = get_cmap(len(bodyparts))\n",
    "\n",
    "comparisonbodyparts = list(set(DataMachine.columns.get_level_values(1)))\n",
    "\n",
    "scale = 1  # for plotting\n",
    "msize = 15   #size of labels\n",
    "\n",
    "scorer_machine = DLCscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Define: img name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagename = 'frame016.png' #'download_1.jpeg.jpeg' #'frame016.png'  #'frame016.png'\n",
    "\n",
    "for imageindex, imagename in tqdm(enumerate(images_names)):\n",
    "\n",
    "\n",
    "    imindex = np.where(\n",
    "                np.array(DataMachine.index.values) == imagename)[0]\n",
    "\n",
    "    # image = io.imread('/is/ps2/calvarez2/DeepLabCut/pose-tensorflow/models/UnaugmentedDataSet_tanyaMay24/data-tanya/' + imagename)\n",
    "    image = io.imread(os.path.join(test_images_path, imagename),mode='RGB')\n",
    "    image = skimage.color.gray2rgb(image) \n",
    "    height, width, channels = image.shape\n",
    "    if(width * height > max_input_size*max_input_size):\n",
    "        factor = (max_input_size*0.9)/max(height, width)\n",
    "        image = cv2.resize(image, None, fx = factor, fy = factor, interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    plane_name , extenstion = imagename.split('.')\n",
    "\n",
    "    if extenstion != 'png':\n",
    "        imagename = plane_name + '.png'\n",
    "\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    if np.ndim(image)==2:\n",
    "        h, w = np.shape(image)\n",
    "    else:\n",
    "        h, w, nc = np.shape(image)\n",
    "\n",
    "    plt.figure(\n",
    "        frameon=False, figsize=(w * 1. / 100 * scale, h * 1. / 100 * scale))\n",
    "    plt.subplots_adjust(\n",
    "        left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.imshow(image, 'bone')\n",
    "    for cc, scorer in enumerate(Scorers):\n",
    "        for c, bp in enumerate(comparisonbodyparts):\n",
    "\n",
    "            plt.plot(   \n",
    "                    DataMachine[scorer_machine][bp]['x'].values[imindex],\n",
    "                    DataMachine[scorer_machine][bp]['y'].values[imindex],\n",
    "                    Labels[0],\n",
    "                    color=Colorscheme(c),#color=Colorscheme[c],#color=Colorscheme[0],\n",
    "                    alpha=.5,\n",
    "                    ms=msize)\n",
    "\n",
    "    plt.xlim(0, w)\n",
    "    plt.ylim(0, h)\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(\n",
    "        left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(labeled_images_path + '/' + imagename , dpi=100) #dpi=100 = original size\n",
    "    plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
